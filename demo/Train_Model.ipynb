{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training:\n",
    "\n",
    "## Introduction:\n",
    "This notebook showcases the training process of the model. Due to the amount of the original images exceeding $700,000$, this demo will only go over the training process on the artificially made images. Additionally, we'll only be using the $I5$ image datasets as the other datasets are require lot's of computational resources. For this example, we'll be using the artificially generated base images. Once again, to go more into depth, please view the `train_model.py` module. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages:\n",
    "Please import the packages below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import all necessary packages.\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join('..')))\n",
    "import src.models.cnn_model as cm\n",
    "import src.utils.file_operations as fo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Working Directories:\n",
    "Please use the following to code to establish the base directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialize the base directory to be in .\\stock_code.\n",
    "base_dir = os.path.abspath(os.path.join('.', '..'))\n",
    "\n",
    "## Uncomment code below to view your current working directory to check if it's correct.\n",
    "# print(base_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize and Compile Model:\n",
    "We'll first initialize our model. Since we're training $I5R5$ images, we'll have to use the model designed for $5$ day interval. This can be done by fetching the $5$ day model from the `StockCNNModel` class in `cnn_model.py` module. After obtaining the required model, we can compile and view it's architecture (shown below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 13, 64)        1024      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 28, 13, 64)       256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 28, 13, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 14, 13, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 14, 13, 128)       123008    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 14, 13, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 14, 13, 128)       0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 7, 13, 128)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 11648)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 15360)             178928640 \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 15360)             0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 15360)             0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 15361     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 179,068,801\n",
      "Trainable params: 179,068,417\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## Choose and compile the necessary model you want to train.\n",
    "model = cm.StockCNNModel('five').generate_model()\n",
    "\n",
    "## Showcase the model's architecture.\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Training Images:\n",
    "After loading in our model, we'll have to load in our training images. This can be done using Tensorflow's built-in function `tf.keras.utils.image_dataset_from_directory`. To properly use the function, we'll first need to define the directory that stores our training images and the training image shape (i.e., height and width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the directory that stores the training images.\n",
    "train_img_dir = os.path.join(base_dir, 'data', 'processed_img', 'artificial_img', 'I5R5', 'base_img', 'training_dataset')\n",
    "\n",
    "## Establish the input shape for the model.\n",
    "input_shape = (32, 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the parameters defined above, we can now create our training and validation datasets using Tensorflow's built-in functions. Validation will be comprised of $30\\%$ of the initial data and our batch size will be $128$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 585 files belonging to 2 classes.\n",
      "Using 410 files for training.\n",
      "Using 175 files for validation.\n"
     ]
    }
   ],
   "source": [
    "## Create training and validation dataset using Tensorflow.\n",
    "train_ds, val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    train_img_dir, \n",
    "    labels = 'inferred', \n",
    "    label_mode = 'binary', \n",
    "    color_mode = 'grayscale', \n",
    "    batch_size = 128, \n",
    "    image_size = input_shape, \n",
    "    shuffle = True, \n",
    "    validation_split = 0.3, \n",
    "    subset = 'both', \n",
    "    seed = 42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our training and validation datasets, we can begin training the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model:\n",
    "To train the model, we'll use the Adam Optimizer with an initial learning rate of $1 \\times 10^{-5}$ and binary cross entropy to calculate error. Our metrics will only consist of tracking the model's accuracy. We'll use $100$ epochs for this training process, yet this number can be different in the `train_model` script. \n",
    "\n",
    "Before training, we'll also need to establish early stopping. This would make sure to stop the training process if our valdiation loss doesn't improve after two epochs and recover the weights with the best performance. This is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the early stopping callback.\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor = 'val_loss', \n",
    "    patience = 2, \n",
    "    restore_best_weights = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using these newly defined variables, we can now begin the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "4/4 [==============================] - 3s 259ms/step - loss: 0.5383 - accuracy: 0.7268 - val_loss: 0.3762 - val_accuracy: 0.8971\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 0.1188 - accuracy: 0.9659 - val_loss: 0.1482 - val_accuracy: 0.9714\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 0.0670 - accuracy: 0.9756 - val_loss: 0.1417 - val_accuracy: 0.9714\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.0618 - accuracy: 0.9756 - val_loss: 0.1008 - val_accuracy: 0.9771\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.0381 - accuracy: 0.9854 - val_loss: 0.1257 - val_accuracy: 0.9771\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 0.0366 - accuracy: 0.9878 - val_loss: 0.1395 - val_accuracy: 0.9771\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26f0cab2440>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Train the model.\n",
    "model.fit(train_ds, epochs = 50, callbacks = [early_stopping], validation_data = val_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Trained Model:\n",
    "After training, you can save the model's weights. Please use the function `save_model` from the `file_operations` module to save the existing weights as a `h5` file. This trained model can later be loaded in and be applied to the testing images (see more in `Model_Evaluation` notebook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the directory that stores the model's weight.\n",
    "models_out_dir = \"[your-path-to-models]\\\\[test_model_name].h5\"\n",
    "\n",
    "## Use function to save the model's weight to designated directory.\n",
    "fo.save_model(model, models_out_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stockenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
